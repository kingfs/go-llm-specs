id: minimax/minimax-m2.1
name: 'MiniMax: MiniMax M2.1'
provider: Minimax
description: |-
  MiniMax-M2.1 is a lightweight, state-of-the-art large language model optimized for coding, agentic workflows, and modern application development. With only 10 billion activated parameters, it delivers a major jump in real-world capability while maintaining exceptional latency, scalability, and cost efficiency.

  Compared to its predecessor, M2.1 delivers cleaner, more concise outputs and faster perceived response times. It shows leading multilingual coding performance across major systems and application languages, achieving 49.4% on Multi-SWE-Bench and 72.5% on SWE-Bench Multilingual, and serves as a versatile agent “brain” for IDEs, coding tools, and general-purpose assistance.

  To avoid degrading this model's performance, MiniMax highly recommends preserving reasoning between turns. Learn more about using reasoning_details to pass back reasoning in our [docs](https://openrouter.ai/docs/use-cases/reasoning-tokens#preserving-reasoning-blocks).
description_cn: |-
  MiniMax-M2.1 是一款轻量级、业界领先的大型语言模型，针对编程、智能体工作流及现代应用开发进行了优化。仅激活 100 亿参数，即可实现真实场景能力的显著跃升，同时保持卓越的延迟表现、可扩展性与成本效益。

  相比前代模型，M2.1 输出更简洁清晰，感知响应速度更快。其在主流系统与应用语言中展现出领先的多语言编程性能，在 Multi-SWE-Bench 上达到 49.4%，在 SWE-Bench Multilingual 上达到 72.5%，可作为 IDE、编程工具及通用助手中的多功能智能体“大脑”。

  为避免性能下降，MiniMax 强烈建议在对话轮次间保留推理过程。更多关于如何通过 reasoning_details 传递推理信息的内容，请参阅[文档](https://openrouter.ai/docs/use-cases/reasoning-tokens#preserving-reasoning-blocks)。
context_length: 196608
max_output: 196608
features:
  - CapChat
  - CapFunctionCall
  - CapJsonMode
  - ModalityTextIn
  - ModalityTextOut
