id: arcee-ai/trinity-large-preview:free
name: 'Arcee AI: Trinity Large Preview (free)'
provider: Arcee-Ai
description: "Trinity-Large-Preview is a frontier-scale open-weight language model from Arcee, built as a 400B-parameter sparse Mixture-of-Experts with 13B active parameters per token using 4-of-256 expert routing. \n\nIt excels in creative writing, storytelling, role-play, chat scenarios, and real-time voice assistance, better than your average reasoning model usually can. But we’re also introducing some of our newer agentic performance. It was trained to navigate well in agent harnesses like OpenCode, Cline, and Kilo Code, and to handle complex toolchains and long, constraint-filled prompts. \n\nThe architecture natively supports very long context windows up to 512k tokens, with the Preview API currently served at 128k context using 8-bit quantization for practical deployment. Trinity-Large-Preview reflects Arcee’s efficiency-first design philosophy, offering a production-oriented frontier model with open weights and permissive licensing suitable for real-world applications and experimentation."
description_cn: |-
  Trinity-Large-Preview 是 Arcee 推出的前沿级开源权重语言模型，采用稀疏混合专家（Mixture-of-Experts）架构，总参数量达 4000 亿，每 token 激活 130 亿参数，使用 256 个专家中选择 4 个的路由机制。

  该模型在创意写作、故事叙述、角色扮演、聊天场景及实时语音助手等任务上表现卓越，远超常规推理模型。同时，我们还引入了部分新型智能体（agentic）能力：模型经过专门训练，可在 OpenCode、Cline 和 Kilo Code 等智能体框架中高效运行，并能处理复杂的工具链及包含大量约束条件的长提示。

  其架构原生支持高达 512k token 的上下文窗口；当前 Preview API 以 8 位量化方式部署，提供 128k 上下文长度，兼顾实用性与性能。Trinity-Large-Preview 体现了 Arcee 以效率优先的设计理念，是一款面向生产环境的前沿开源模型，具备宽松的许可协议，适用于实际应用与实验探索。
context_length: 131000
features:
  - CapChat
  - CapFunctionCall
  - CapJsonMode
  - ModalityTextIn
  - ModalityTextOut
