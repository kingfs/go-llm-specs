id: meta-llama/llama-3.2-11b-vision-instruct
name: 'Meta: Llama 3.2 11B Vision Instruct'
provider: Meta
description: |-
    Llama 3.2 11B Vision is a multimodal model with 11 billion parameters, designed to handle tasks combining visual and textual data. It excels in tasks such as image captioning and visual question answering, bridging the gap between language generation and visual reasoning. Pre-trained on a massive dataset of image-text pairs, it performs well in complex, high-accuracy image analysis.

    Its ability to integrate visual understanding with language processing makes it an ideal solution for industries requiring comprehensive visual-linguistic AI applications, such as content creation, AI-driven customer service, and research.

    Click here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD_VISION.md).

    Usage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).
description_cn: |-
    Llama 3.2 11B Vision 是一款拥有 110 亿参数的多模态模型，专为处理视觉与文本融合任务而设计，在图像描述生成和视觉问答等任务中表现卓越，有效弥合了语言生成与视觉推理之间的鸿沟。该模型在海量图文对数据集上预训练，在复杂高精度图像分析任务中表现出色。

    其将视觉理解与语言处理相结合的能力，使其成为内容创作、AI 驱动的客户服务及科研等需要综合视觉-语言 AI 应用领域的理想解决方案。

    点击[此处](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD_VISION.md)查看原始模型卡。

    使用本模型需遵守 [Meta 可接受使用政策](https://www.llama.com/llama3/use-policy/)。
context_length: 131072
max_output: 16384
price_in: 4.9e-08
price_out: 4.9e-08
features:
    - CapChat
    - CapJsonMode
    - ModalityImageIn
    - ModalityTextIn
    - ModalityTextOut
