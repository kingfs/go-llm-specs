id: meta-llama/llama-4-maverick
name: 'Meta: Llama 4 Maverick'
provider: Meta
description: |-
  Llama 4 Maverick 17B Instruct (128E) is a high-capacity multimodal language model from Meta, built on a mixture-of-experts (MoE) architecture with 128 experts and 17 billion active parameters per forward pass (400B total). It supports multilingual text and image input, and produces multilingual text and code output across 12 supported languages. Optimized for vision-language tasks, Maverick is instruction-tuned for assistant-like behavior, image reasoning, and general-purpose multimodal interaction.

  Maverick features early fusion for native multimodality and a 1 million token context window. It was trained on a curated mixture of public, licensed, and Meta-platform data, covering ~22 trillion tokens, with a knowledge cutoff in August 2024. Released on April 5, 2025 under the Llama 4 Community License, Maverick is suited for research and commercial applications requiring advanced multimodal understanding and high model throughput.
description_cn: |-
  Llama 4 Maverick 17B Instruct（128E）是 Meta 推出的高性能多模态语言模型，基于混合专家（MoE）架构，包含 128 个专家，每次前向传播激活 170 亿参数（总计 4000 亿参数）。该模型支持 12 种语言的多语言文本与图像输入，并生成多语言文本与代码输出。Maverick 针对视觉-语言任务进行了优化，通过指令微调实现类助手行为、图像推理及通用多模态交互。

  Maverick 采用早期融合（early fusion）实现原生多模态能力，并支持 100 万 token 的上下文窗口。其训练数据涵盖约 22 万亿 token，包括精选的公开数据、授权数据及 Meta 平台数据，知识截止于 2024 年 8 月。该模型于 2025 年 4 月 5 日依据 Llama 4 社区许可证发布，适用于需要高级多模态理解与高吞吐性能的研究及商业应用。
context_length: 1048576
max_output: 16384
features:
  - CapChat
  - CapFunctionCall
  - CapJsonMode
  - ModalityImageIn
  - ModalityTextIn
  - ModalityTextOut
