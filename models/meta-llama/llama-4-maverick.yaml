description_cn: |-
    Llama 4 Maverick 17B Instruct（128E）是 Meta 推出的高性能多模态语言模型，基于混合专家（MoE）架构，包含 128 个专家，每次前向传播激活 170 亿参数（总计 4000 亿参数）。该模型支持 12 种语言的多语言文本与图像输入，并生成多语言文本与代码输出。Maverick 针对视觉-语言任务进行了优化，通过指令微调实现类助手行为、图像推理及通用多模态交互。

    Maverick 采用早期融合（early fusion）实现原生多模态能力，并支持 100 万 token 的上下文窗口。其训练数据涵盖约 22 万亿 token，包括精选的公开数据、授权数据及 Meta 平台数据，知识截止于 2024 年 8 月。该模型于 2025 年 4 月 5 日依据 Llama 4 社区许可证发布，适用于需要高级多模态理解与高吞吐性能的研究及商业应用。
id: meta-llama/llama-4-maverick
