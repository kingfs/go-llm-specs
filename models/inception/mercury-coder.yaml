id: inception/mercury-coder
name: 'Inception: Mercury Coder'
provider: Inception
description: Mercury Coder is the first diffusion large language model (dLLM). Applying a breakthrough discrete diffusion approach, the model runs 5-10x faster than even speed optimized models like Claude 3.5 Haiku and GPT-4o Mini while matching their performance. Mercury Coder's speed means that developers can stay in the flow while coding, enjoying rapid chat-based iteration and responsive code completion suggestions. On Copilot Arena, Mercury Coder ranks 1st in speed and ties for 2nd in quality. Read more in the [blog post here](https://www.inceptionlabs.ai/blog/introducing-mercury).
description_cn: Mercury Coder 是全球首款扩散式大语言模型（dLLM）。该模型采用突破性的离散扩散方法，运行速度比 Claude 3.5 Haiku 和 GPT-4o Mini 等已优化速度的模型快 5–10 倍，同时性能相当。其卓越的速度使开发者在编码时能保持流畅状态，享受快速的聊天式迭代和响应迅速的代码补全建议。在 Copilot Arena 中，Mercury Coder 在速度方面排名第一，质量方面并列第二。更多详情请参阅[此博客文章](https://www.inceptionlabs.ai/blog/introducing-mercury)。
context_length: 128000
max_output: 16384
price_in: 2.5e-07
price_out: 1e-06
features:
  - CapChat
  - CapFunctionCall
  - CapJsonMode
  - ModalityTextIn
  - ModalityTextOut
